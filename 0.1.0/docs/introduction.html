<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="generator" content="Publish.jl" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="" />
    <title>DLPipelines.jl</title>
    <link rel="stylesheet" href="..&#x2F;normalize.css" />
    <link rel="stylesheet" href="..&#x2F;tabulator_simple.min.css" />
    <link rel="stylesheet" href="..&#x2F;publish.css" />
    <link rel="stylesheet" href="..&#x2F;default.min.css" />
    <script src="..&#x2F;versions.js"></script>
    <script src="..&#x2F;lunr.js"></script>
    <script src="..&#x2F;highlight.min.js"></script>
    <script src="..&#x2F;tabulator.min.js"></script>
    <script src="..&#x2F;julia.min.js"></script>
    <script src="..&#x2F;julia-repl.min.js"></script>
    <script src="..&#x2F;publish.js"></script>
    <link rel="stylesheet" href="custom.css" />
    
</head>
<body>
    <div class="menu">
        <svg id="menu-toggler" title="Contents" onclick="toggleIndexPage();" width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2 6C2 5.44772 2.44772 5 3 5H21C21.5523 5 22 5.44772 22 6C22 6.55228 21.5523 7 21 7H3C2.44772 7 2 6.55228 2 6Z" fill="currentColor" /><path d="M2 12.0322C2 11.4799 2.44772 11.0322 3 11.0322H21C21.5523 11.0322 22 11.4799 22 12.0322C22 12.5845 21.5523 13.0322 21 13.0322H3C2.44772 13.0322 2 12.5845 2 12.0322Z" fill="currentColor" /><path d="M3 17.0645C2.44772 17.0645 2 17.5122 2 18.0645C2 18.6167 2.44772 19.0645 3 19.0645H21C21.5523 19.0645 22 18.6167 22 18.0645C22 17.5122 21.5523 17.0645 21 17.0645H3Z" fill="currentColor" /></svg>
        <input id="search-input" placeholder="Search">
        <select id="version-selector"></select>
    </div>
    <main id="page"><article><h1 id="introduction"><a href="#introduction" class="anchor"></a>Introduction</h1>
<p>In supervised deep learning, we’re usually trying to solve a problem by finding a mapping from some inputs to some targets. Let’s call this a <em>task</em>. Consider for example this table:</p>
<table><thead><tr><th align="left">Task</th><th align="left">Input</th><th align="left">Target</th></tr></thead><tbody><tr><td align="left">Image classification</td><td align="left">Image</td><td align="left">Category</td></tr><tr><td align="left">Semantic segmentation</td><td align="left">Image</td><td align="left">Category per pixel</td></tr><tr><td align="left">Object detection</td><td align="left">Image</td><td align="left">Bounding boxes</td></tr><tr><td align="left">Text completion</td><td align="left">Text</td><td align="left">Next character</td></tr></tbody></table>
<p>There are usually multiple ways to go about solving a task. We call a <em>method</em> a concrete approach to a task that has a learnable part (the model) but also defines how</p>
<ul>
<li>inputs and targets are <em>encoded</em> into a form that can be fed to and output by the model</li>
<li>model outputs are <em>decoded</em> to obtain target predictions; and</li>
</ul>
<p>os an example method, consider the commmon way of approaching the task of image classification:</p>
<ul>
<li>images are encoded into normalized 3D-Arrays of <code>Float32</code>s and categories into one-hot vectors</li>
<li>the predicted probability distributions can be decoded into a category by finding the index of the highest score; and</li>
<li>the model takes in batches of encoded inputs and output batches of encoded targets</li>
</ul>
<p>An additional complication comes from the fact that the encoding and decoding step may differ based on situation. For example, during training we often want to apply some augmentation when encoding that would be detrimental to performance during inference.</p>
<h2 id="in-code"><a href="#in-code" class="anchor"></a>In code</h2>
<p>The most important type is <a href="../docstrings/DLPipelines.Method.html"><code>Method</code></a> which represents a method for a <a href="../docstrings/DLPipelines.Task.html"><code>Task</code></a>. All interface functions will dispatch on <code>Method</code>. It should be a concrete <code>struct</code> containing necessary configuration.</p>
<p>Let’s give the other concepts variable names and generic types so we can refer to them more easily:</p>
<ul>
<li><code>task::Task</code>: a task mapping <code>I</code> to <code>T</code></li>
<li><code>method::Method{Task}</code>: a method implementing a task using encodings <code>X</code> and <code>Y</code></li>
<li><code>input::I</code>: an input</li>
<li><code>target::T</code>: a target</li>
<li><code>x::X</code>: an encoded input</li>
<li><code>y::Y</code>: an encoded target</li>
<li><code>ŷ::Ŷ</code>: a model output</li>
<li><code>inputs</code>, <code>targets</code>, <code>xs</code>, <code>ys</code>: batches of the respective data</li>
<li><code>model</code>: a function <code>(X) -&gt; Ŷ</code></li>
<li><code>lossfn</code>: a function <code>(Ŷ, Y) -&gt; Number</code></li>
</ul>
<p>So a <code>Task</code> is an abstract type representing a mapping from some input type <code>I</code> to target type <code>T</code>. A <code>Method{T}</code> implements the task <code>T</code> by using encoded representations <code>X</code> and <code>Y</code>.</p>
<p>As a concrete example, consider image classification:</p>
<ul>
<li><code>task::ImageClassificationTask</code>: subtype of <code>Task</code></li>
<li><code>method::ImageClassification</code>: subtype of <code>Method{ImageClassificationTask}</code></li>
<li><code>input::AbstractMatrix{2, &lt;:Colorant}</code>: an image</li>
<li><code>target::Int</code> the category that the image belongs to</li>
<li><code>x::AbstractArray{Float32, 3}</code>: a normalized 3D-array with dimensions <em>height, width, channels</em></li>
<li><code>y::AbstractVector{Float32}</code>: one-hot encoding of category</li>
<li><code>ŷ::AbstractVector{Float32̂}</code>: softmax probabilities</li>
</ul>
<h2 id="core-pipelines"><a href="#core-pipelines" class="anchor"></a>Core pipelines</h2>
<p>To give a motivation for the interface, consider the two most important pipelines in a deep learning application: training and inference.</p>
<p><em>Note: I’m purposely neglecting batching here (for now), as it doesn’t change the semantics of the data pipeline, just the practical implementation.</em></p>
<p>During <strong>inference</strong>, we have an input and obtain a target prediction. Writing this with types gives us:</p>
<pre><code class="language-text">     encode       model       decode
::I -------&gt; ::X ------&gt; ::Ŷ -------&gt; ::T
</code></pre>
<p>When <strong>training</strong>, we first encode both input and target, including any augmentation. We then feed the encoded input to the model and compare its output with the true encoded target.</p>
<pre><code class="language-text">          encode            lossfn(model(X), Y)
::(I, 0) -------&gt; ::(X, Y) --------------------&gt; loss
</code></pre>
<p>From those two pipelines, we can extract the following transformations:</p>
<ul>
<li><code>I -&gt; X</code> encoding input</li>
<li><code>Ŷ -&gt; T</code> decoding model output</li>
<li><code>(I, T) -&gt; (X, Y)</code> encoding input and target</li>
</ul>
<p>These make up the <a href="interfaces/core.html">core interface</a>.</p>
</article>
        <div id="page-navigation">
            <a id="previous-page" title="Previous" href="..&#x2F;README.html"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M16.2426 6.34317L14.8284 4.92896L7.75739 12L14.8285 19.0711L16.2427 17.6569L10.5858 12L16.2426 6.34317Z" fill="currentColor" /></svg></a>
            <a id="next-page" title="Next" href="usage.html"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.5858 6.34317L12 4.92896L19.0711 12L12 19.0711L10.5858 17.6569L16.2427 12L10.5858 6.34317Z" fill="currentColor" /></svg></a>
        </div>
    </main>
    <nav id="toc"><ul>
<li><a href="../README.html">Readme</a></li>
<li><a href="../docs/introduction.html">Introduction</a></li>
<li><a href="../docs/usage.html">Usage</a></li>
</ul>
<h3 id="library"><a href="../#library" class="anchor"></a>Library</h3>
<ul>
<li><a href="../docs/interfaces/overview.html">Interfaces</a>
<ul>
<li><a href="../docs/interfaces/core.html">Core interface</a></li>
</ul>
</li>
<li><a href="../docs/methods/methods.html">Methods</a>
<ul>
<li><a href="../docs/methods/imageclassification.html">Image classification</a></li>
</ul>
</li>
<li><a href="../docs/transforms.html">Transforms</a></li>
</ul>
<h3 id="source-code"><a href="../#source-code" class="anchor"></a>Source code</h3>
<ul>
<li><a href="../src/DLPipelines.html"><code>DLPipelines.jl</code></a></li>
<li><a href="../src/task.html"><code>task.jl</code></a></li>
<li><a href="../src/api.html"><code>api.jl</code></a></li>
<li><a href="../src/transforms/spatial.html"><code>transforms/spatial.jl</code></a></li>
<li><a href="../src/transforms/imagepreprocessing.html"><code>transforms/imagepreprocessing.jl</code></a></li>
<li><a href="../src/methods/imageclassification.html"><code>methods/imageclassification.jl</code></a></li>
</ul>
</nav>
    <footer>
        Built with <a target="_blank" href="https://github.com/MichaelHatherly/Publish.jl">Publish.jl</a> and the <a target="_blank" href="https://julialang.org">Julia Language.</a>
    </footer>
    <script>hljs.initHighlightingOnLoad();</script>
</body>
</html>
