[{"body":"Optional functions Description  shouldbatch  Defines whether the model for a method should take batches of  encoded inputs .  The default is  true .  What is the  context  argument? We often want to apply data augmentation during training but not during validation or inference .  You can dispatch on  context  to define different behavior for the different situations .  See  Context  to see the available options . When should I implement  encode  vs .   encodetarget ? See  encode .","id":"docs/interfaces/core.html#section"},{"body":"Interfaces DLPipelines . jl has multiple interfaces that you can implement for your  LearningMethod s . Core interface , for inference and training pipelines .  Everything you need to use  predict ,  predictbatch  and  methoddataset . encode encodeinput encodetarget decodeŷ Buffered interface, to enable allocation - free pipelines .  Mimicks the core interface . encode! encodeinput! encodetarget! decodeŷ! Interpretation interface, for visualizing and making sense of the data at different steps . interpretinput interprettarget interpretx interprety interpretŷ Training interface . methodlossfn methodmodel","id":"docs/interfaces/overview.html#interfaces"},{"body":"Keyword arguments batchsize = 16 shuffle = true : Whether to shuffle the training data container validbsfactor = 2 : Factor to multiply batchsize for validation data loader with (validation batches can be larger since no GPU memory is needed for the backward pass) All remaining keyword arguments are passed to  DataLoader .","id":"docstrings/DLPipelines.methoddataloaders.html#keyword-arguments"},{"body":"private   mocksample   —   function Generate a random  sample  compatible with  method .","id":"docstrings/DLPipelines.mocksample.html"},{"body":"private   mocktarget   —   function Generate a random  target  compatible with  method .","id":"docstrings/DLPipelines.mocktarget.html"},{"body":"DLPipelines DLPipelines . jl  is an interface for defining deep learning data pipelines .  This includes every data transformation beside the model itself: preprocessing and augmenting the data before feeding it into the model, and decoding the model ’ s outputs to targets . It is used in  FastAI . jl  to provide an easy - to - use interface for common learning tasks . See  the documentation  for more information on implementing the interface .","id":"README.html#dlpipelines"},{"body":"Core interface First you need to define a custom  LearningMethod  (and possibly a  Task ) . Then implement the following functions by dispatching on the method . Required functions Description  encode  Encodes a sample containing input and target so they can be used for a training step  encodeinput  Encodes an input so that it can be fed to a model  encodetarget  Encodes a target so that it can be compared to a model output using a loss function  decodeŷ  Decodes the output of a model into a target","id":"docs/interfaces/core.html#core-interface"},{"body":"In code Let ’ s give those concepts variable names and generic types so we can refer to them more easily . Concept Abstract code Image classification Method  Method{Task}   ImageClassification <: Method{ImageClassificationTask}  Input  input::I   image::AbstractMatrix{<:Colorant}  Target  target::T   category::String  Encoded input  x::X   x::AbstractArray{Float32, 3}  Encoded target  y::Y   y::Vector{Float32}  Model output  ŷ::Ŷ   y::Vector{Float32}  So a  Task  is an abstract type representing a mapping from some input type  I  to target type  T .  A  Method{T}  implements the task  T  by using encoded representations  X  and  Y .  For example, the  ImageClassificationTask  task represents a mapping from an image to a category .  The concrete  LearningMethod   ImageClassification  implements that task using the encoded representations defined in the table above . The most important type is  LearningMethod  which represents a method for a learning task .  All interface functions will dispatch on  LearningMethod .  It should be a concrete  struct  containing necessary configuration .","id":"docs/introduction.html#in-code"},{"body":"public   encode   —   function Encode a  sample  containing both input and target . If  sample  is a  Tuple  of (input, target), the default behavior is to pass them to  encodeinput  and  encodetarget .","id":"docstrings/DLPipelines.encode.html"},{"body":"private   methoddataloaders   —   function Create training and validation  DataLoader s from two data containers  (traindata, valdata) . If only one container  data  is passed, splits it into two with  pctgvalid % of the data going into the validation split .","id":"docstrings/DLPipelines.methoddataloaders.html"},{"body":"public   encodetarget   —   function Encode  target  into a representation that a model for  task  outputs .","id":"docstrings/DLPipelines.encodetarget.html"},{"body":"private   mockmodel   —   function Generate a random  model  compatible with  method .","id":"docstrings/DLPipelines.mockmodel.html"},{"body":"Remarks When should I implement  encode  vs .   encodeinput  and  encodetarget ? In simple cases like image classification we can encode the inputs and targets separately and you should prefer  encodeinput  and  encodetarget . The default implementation for  encode  when given an  (input, target) - tuple is to delegate to  encodeinput  and  encodetarget . In other cases like semantic segmentation, however, we want to apply stochastic augmentations to both image and segmentation mask .  In that case you need to encode both at the same time using  encode . Another situation where  encode  is needed is when  sample  is not a tuple of  (input, target) , for example a  Dict  that includes additional information .   encode  still needs to return an  (x, y) - tuple, though .","id":"docstrings/DLPipelines.encode.html#remarks"},{"body":"private   predictbatch   —   function Predict  targets  from a vector of  inputs  using  model  by batching them . Optionally apply function  device  to batch before passing to  model  and use  context  instead of the default  Inference .","id":"docstrings/DLPipelines.predictbatch.html"},{"body":"public   decodeŷ   —   function Decodes a model output into a target .","id":"docstrings/DLPipelines.decodeŷ.html"},{"body":"private   methodlossfn   —   function Default loss function to use when training models for  method .","id":"docstrings/DLPipelines.methodlossfn.html"},{"body":"public   LearningMethod   —   type Represents a concrete approach for solving a learning task . See  core interface  for more on how to implement custom  LearningMethod s","id":"docstrings/DLPipelines.LearningMethod.html"},{"body":"private   predict   —   function Predict a  target  from  input  using  model .  Optionally apply function  device to  x  before passing to  model  and use  context  instead of the default context  Inference .","id":"docstrings/DLPipelines.predict.html"},{"body":"private   checkmethod_interpretation   —   function Check if  method  conforms to the  core interface . sample  and  model  are used for testing .  If you have implemented the testing interface and don ’ t supply these as arguments,  mocksample(method)  and mockmodel(method)  will be used .","id":"docstrings/DLPipelines.checkmethod_interpretation.html"},{"body":"private   shouldbatch   —   function Whether models for  method  take in batches of inputs .  Default is  true .","id":"docstrings/DLPipelines.shouldbatch.html"},{"body":"Core pipelines We neglect batching here, as it doesn ’ t change the semantics of the data pipeline, just the practical implementation . To give a motivation for the interface, consider the two most important pipelines in a deep learning application: training and inference . During inference, we have an input and obtain a target prediction .  Writing this with types gives us: When training, we first encode both input and target, including any augmentation .  We then feed the encoded input to the model and compare its output with the true encoded target . From those two pipelines, we can extract the following transformations: I -> X  encoding input Ŷ -> T  decoding model output (I, T) -> (X, Y)  encoding input and target These make up the  core interface .","id":"docs/introduction.html#core-pipelines"},{"body":"Introduction","id":"docs/introduction.html#introduction"},{"body":"Terminology In supervised deep learning, we ’ re usually trying to solve a problem by finding a mapping from some input to some target .  Let ’ s call this a  task .  Consider the following tasks: Task Input Target Image classification Image Category Semantic segmentation Image Category per pixel Object detection Image Bounding boxes Text completion Text Next character There are usually multiple ways to go about solving a task .  We call a  method  a concrete approach to a task that has a learnable part (the model) but also defines how inputs and targets are  encoded  into a form that can be fed to and output by the model model outputs are  decoded  to obtain target predictions; and As an example method, consider the commmon way of approaching the task of image classification: images are encoded into normalized 3D - Arrays of  Float32 s and categories into one - hot vectors the predicted probability distributions can be decoded into a category by finding the index of the highest score; and the model takes in batches of encoded inputs and output batches of encoded targets An additional complication comes from the fact that the encoding and decoding step may differ based on the context .  For example, during training we often want to augment the inputs which would be detrimental to performance during inference .","id":"docs/introduction.html#terminology"},{"body":"Examples Basic usage: Explicit validation data container and no shuffling of training container: Customizing the  DataLoader","id":"docstrings/DLPipelines.methoddataloaders.html#examples"},{"body":"private   decodey   —   function Decodes an encoded target back into a target . Defaults to using  decodeŷ","id":"docstrings/DLPipelines.decodey.html"},{"body":"public   encodeinput   —   function Encode  input  into a representation that a model for  method takes as input . See also  LearningMethod ,  encode , and  encodetarget .","id":"docstrings/DLPipelines.encodeinput.html"},{"body":"public   Context   —   type Represents a context in which a data transformation is made .  This allows using dispatching for varying behavior, for example, to apply augmentations only during training or use non - destructive cropping during inference . Available contexts are  Training ,  Validation  and Inference .","id":"docstrings/DLPipelines.Context.html"},{"body":"private   methoddataset   —   parametric type Transform data container  data  of samples into a data container of  (x, y) - pairs . Maps  encode(method, context, sample)  over the observations in  data .","id":"docstrings/DLPipelines.methoddataset.html"},{"body":"private   mockinput   —   function Generate a random  input  compatible with  method .","id":"docstrings/DLPipelines.mockinput.html"},{"body":"Functionality With the  LearningMethod  interface implemented, you can use some utilities included in DLPipelines . jl: methoddataset : Transform a data container of inputs and targets to one of  s and  s . methoddataloaders : Create a pair of training and validation data iterators that can be used directly in training loops .  Uses  DataLoaders . jl checkmethod : Check interface conformance of a  method  implementation . predict ,  predictbatch : Use a model to predict a target from an input (or batches of each) You may also use  checkmethod_core  and  checkmethod_interpretation  to check the interfaces separately .","id":"docs/functionality.html#functionality"},{"body":"private   MethodDataset   —   parametric type Transform data container  data  of samples into a data container of  (x, y) - pairs . Maps  encode(method, context, sample)  over the observations in  data .","id":"docstrings/DLPipelines.MethodDataset.html"},{"body":"private   checkmethod   —   function Check if  method  conforms to the  DLPipelines.jl  interfaces . sample  and  model  are used for testing .  If you have implemented the testing interface and don ’ t supply these as arguments,  mocksample(method)  and mockmodel(method)  will be used . Checks  core  and  interpretation  interfaces .","id":"docstrings/DLPipelines.checkmethod.html"},{"body":"private   checkmethod_core   —   function Check if  method  conforms to the  core interface . sample  and  model  are used for testing .  If you have implemented the testing interface and don ’ t supply these as arguments,  mocksample(method)  and mockmodel(method)  will be used .","id":"docstrings/DLPipelines.checkmethod_core.html"},{"body":"private   methodmodel   —   function Construct a model for  method  from a backbone architecture, for example by attaching a method - specific head model .","id":"docstrings/DLPipelines.methodmodel.html"}]