[{"body":"See  introduction  and  core interface .","id":"src/task.html"},{"body":"Interfaces Find out how to implement custom  Method s . Core interface , for inference and training pipelines . Interpretation interface .","id":"docs/interfaces/overview.html#interfaces"},{"body":"Task","id":"src/task.html#task"},{"body":"DLPipelines . jl DLPipelines . jl  is an interface for defining deep learning data pipelines .  This includes every data transformation beside the model itself: preprocessing and augmenting the data before feeding it into the model, and decoding the model ’ s outputs to targets . task.jl  defines the  task and method interface . api.jl  defines the user - facing functions . The transforms are defined under  transforms/ : transforms/spatial.jl transforms/imagepreprocessing.jl The  Method  implementations live under  methods/ : methods/imageclassification.jl","id":"src/DLPipelines.html#dlpipelinesjl"},{"body":"Types We start off by defining the abstract types that will be used for dispatch .","id":"src/task.html#types"},{"body":"DLPipelines DLPipelines . jl  is an interface for defining deep learning data pipelines .  This includes every data transformation beside the model itself: preprocessing and augmenting the data before feeding it into the model, and decoding the model ’ s outputs to targets . With the interface defined, it ’ s dead simple to create data iterators for training and inference pipelines .  See  image classification  as a motivating example . The package was born from the realization that the data pipeline plays a large role in many deep learning projects .  It abstracts the pipeline into steps that lend themselves to building training, inference and other pipelines . Read on here  to find out more about the interface . DLPipelines . jl  is currently in a pre - implementation phase where the focus is on exploring suitable interfaces .","id":"README.html#dlpipelines"},{"body":"Core interface First you need to  define a custom  Method  (and possibly a  Task ) . Then implement the following functions by dispatching on the method .","id":"docs/interfaces/core.html#core-interface"},{"body":"Context  and concrete types","id":"src/task.html#context-and-concrete-types"},{"body":"In code The most important type is  Method  which represents a method for a  Task .  All interface functions will dispatch on  Method .  It should be a concrete  struct  containing necessary configuration . Let ’ s give the other concepts variable names and generic types so we can refer to them more easily: task::Task : a task mapping  I  to  T method::Method{Task} : a method implementing a task using encodings  X  and  Y input::I : an input target::T : a target x::X : an encoded input y::Y : an encoded target ŷ::Ŷ : a model output inputs ,  targets ,  xs ,  ys : batches of the respective data model : a function  (X) -> Ŷ lossfn : a function  (Ŷ, Y) -> Number So a  Task  is an abstract type representing a mapping from some input type  I  to target type  T .  A  Method{T}  implements the task  T  by using encoded representations  X  and  Y . As a concrete example, consider image classification: task::ImageClassificationTask : subtype of  Task method::ImageClassification : subtype of  Method{ImageClassificationTask} input::AbstractMatrix{2, <:Colorant} : an image target::Int  the category that the image belongs to x::AbstractArray{Float32, 3} : a normalized 3D - array with dimensions  height, width, channels y::AbstractVector{Float32} : one - hot encoding of category ŷ::AbstractVector{Float32̂} : softmax probabilities","id":"docs/introduction.html#in-code"},{"body":"See  ImagePreprocessing .","id":"src/transforms/imagepreprocessing.html"},{"body":"Types input::AbstractMatrix{2, <:Colorant} : an image target::Int  the category that the image belongs to x::AbstractArray{Float32, 3} : a normalized 3D - array with dimensions  height, width, channels y::AbstractVector{Float32} : one - hot encoding of category","id":"docstrings/DLPipelines.ImageClassification.html#types"},{"body":"Model input size:  (sz..., ch, batch)  where  ch  depends on color type  C . output size:  (nclasses, batch)","id":"docstrings/DLPipelines.ImageClassification.html#model"},{"body":"public   encode   —   function Encode a  sample  containing both input and target  . If  sample  is a  Tuple  of (input, target), the default behavior is to pass them to  encodeinput  and  encodetarget","id":"docstrings/DLPipelines.encode.html"},{"body":"Method","id":"src/task.html#method"},{"body":"core interface implementation","id":"src/methods/imageclassification.html"},{"body":"public   encodetarget   —   function Encode  target  into a representation that a model for  task  outputs .","id":"docstrings/DLPipelines.encodetarget.html"},{"body":"Usage From a  Method  implementation, we can derive some useful functionality . predict (method, model, input)  predicts a target from an input dataiter (method, data, batchsize)  creates a data iterator from container  data  using  DataLoaders . jl  that can be used directly in a training loop","id":"docs/usage.html#usage"},{"body":"Image classification See  ImageClassification ’ s for complete documentation of its arguments Let ’ s explore what you can do with the  Method  interface implemented .  We ’ re using DLDatasets . jl  to access  ImageNette , a small image classification dataset .  Install the package using ]add https://github.com/lorenzoh/DLDatasets.jl With the packages imported, loading the dataset is straightforward: As you can see, every observation consists of an image and a category label: We can also retrieve the 10 different categories from the dataset ’ s metadata: Of","id":"docs/methods/imageclassification.html#image-classification"},{"body":"Remarks When should I implement  encode  vs .   encodeinput  and  encodetarget ? In simple cases like image classification we can encode the inputs and targets separately and you should prefer  encodeinput  and  encodetarget . The default implementation for  encode  when given an  (input, target) - tuple is to delegate to  encodeinput  and  encodetarget . In other cases like semantic segmentation, however, we want to apply stochastic augmentations to both image and segmentation mask .  In that case you need to encode both at the same time using  encode . Another situation where  encode  is needed is when  sample  is not a tuple of  (input, target) , for example a  Dict  that includes additional information .   encode  still needs to return an  (x, y) - tuple, though .","id":"docstrings/DLPipelines.encode.html#remarks"},{"body":"private   decodeŷ   —   function Decodes a model output into a target .","id":"docstrings/DLPipelines.decodeŷ.html"},{"body":"Optional functions shouldbatch (method)  defines whether the model for a method should take batches of encoded inputs .  The default is  true .","id":"docs/interfaces/core.html#optional-functions"},{"body":"Image classification  Method With the dataset ready, we can create an instance of  ImageClassification . The only required argument is  categories :","id":"docs/methods/imageclassification.html#image-classification-method"},{"body":"public   ImagePreprocessing   —   struct Converts an image to a color, then to a 3D - tensor and finally normalizes the values using  means  and  stds . If no  means  or  stds  are given, use ImageNet statistics .","id":"docstrings/DLPipelines.ImagePreprocessing.html"},{"body":"private   shouldbatch   —   function Whether models for  method  take in batches of inputs .  Default is  true .","id":"docstrings/DLPipelines.shouldbatch.html"},{"body":"private   makeitem   —   function Tries to assign a  DataAugmentation.Item  from  data  based on its type . args  are passed to the chosen   Item  constructor . AbstractMatrix{<:Colorant}   - >  Image Vector{<:Union{Nothing, SVector}}   - >  Keypoints","id":"docstrings/DLPipelines.makeitem.html"},{"body":"Core pipelines To give a motivation for the interface, consider the two most important pipelines in a deep learning application: training and inference . Note: I ’ m purposely neglecting batching here (for now), as it doesn ’ t change the semantics of the data pipeline, just the practical implementation . During  inference , we have an input and obtain a target prediction .  Writing this with types gives us: When  training , we first encode both input and target, including any augmentation .  We then feed the encoded input to the model and compare its output with the true encoded target . From those two pipelines, we can extract the following transformations: I -> X  encoding input Ŷ -> T  decoding model output (I, T) -> (X, Y)  encoding input and target These make up the  core interface .","id":"docs/introduction.html#core-pipelines"},{"body":"public   Task   —   type Represents a mapping from high - level types I  to  T . See also  Method .","id":"docstrings/DLPipelines.Task.html"},{"body":"Introduction In supervised deep learning, we ’ re usually trying to solve a problem by finding a mapping from some inputs to some targets .  Let ’ s call this a  task .  Consider for example this table: Task Input Target Image classification Image Category Semantic segmentation Image Category per pixel Object detection Image Bounding boxes Text completion Text Next character There are usually multiple ways to go about solving a task .  We call a  method  a concrete approach to a task that has a learnable part (the model) but also defines how inputs and targets are  encoded  into a form that can be fed to and output by the model model outputs are  decoded  to obtain target predictions; and os an example method, consider the commmon way of approaching the task of image classification: images are encoded into normalized 3D - Arrays of  Float32 s and categories into one - hot vectors the predicted probability distributions can be decoded into a category by finding the index of the highest score; and the model takes in batches of encoded inputs and output batches of encoded targets An additional complication comes from the fact that the encoding and decoding step may differ based on situation .  For example, during training we often want to apply some augmentation when encoding that would be detrimental to performance during inference .","id":"docs/introduction.html#introduction"},{"body":"Remarks What is the  context  argument? We often want to apply data augmentation during training but not during validation or inference .  You can dispatch on  context  to define different behavior for the different situations .  See  Context  to see the available options . When should I implement  encode  vs .   encodetarget ? See  encode .","id":"docs/interfaces/core.html#remarks"},{"body":"public   Method   —   parametric type Represents a concrete approach for solving a Task . See  core interface  for more on how to implement custom  Method s","id":"docstrings/DLPipelines.Method.html"},{"body":"public   ImageClassification   —   struct A  Method  for multi - class image classification using softmax probabilities . categories  is a vector of the category labels .  Alternatively, you can pass an integer . Images are resized to  sz . During training, a random crop is used and  augmentations , a  DataAugmentation.Transform are applied .","id":"docstrings/DLPipelines.ImageClassification.html"},{"body":"private   decodey   —   function Decodes an encoded target back into a target . Defaults to using  decodeŷ","id":"docstrings/DLPipelines.decodey.html"},{"body":"Methods DLPipelines . jl  comes with some  Method s already implemented . ImageClassification","id":"docs/methods/methods.html#methods"},{"body":"Core interface Next the core interface is defined: encode encodeinput encodetarget decodeŷ decodey shouldbatch","id":"src/task.html#core-interface"},{"body":"Required functions encodeinput (method, context, input) -> x  encodes an input so that it can be fed to a model decodeŷ (method, context, ŷ) -> target  decodes the output of a model into a target either encode (method, context, sample) -> (x, y)  encodes a sample containing input and target so they can be used for a training step encodetarget (method, context, target) -> y encodes a target so that it can be compared to a model output using a loss function","id":"docs/interfaces/core.html#required-functions"},{"body":"Transforms Transforms are building blocks that can help you implementing the interfaces for custom  Method s .  Using them is completely optional . SpatialTransforms ImagePreprocessing","id":"docs/transforms.html#transforms"},{"body":"public   Context   —   type Represents a context in which a data transformation is made .  This allows using dispatching for varying behavior, for example, to apply augmentations only during training or use non - destructive cropping during inference . Available contexts are  Training ,  Validation  and Inference .","id":"docstrings/DLPipelines.Context.html"},{"body":"See  SpatialTransforms .","id":"src/transforms/spatial.html"},{"body":"public   encodeinput   —   function Encode  input  into a representation that a model for  method takes as input . See also  Method ,  encode , and  encodetarget .","id":"docstrings/DLPipelines.encodeinput.html"},{"body":"public   SpatialTransforms   —   struct Transformation that resizes images and keypoints to  size . In context  Training , applies  augmentations .","id":"docstrings/DLPipelines.SpatialTransforms.html"}]