[{"body":"Encoding Decoding Inference Interpretation Ideas","id":"src/task.html"},{"body":"Methods interface The Method interface specifies building blocks for constructing data pipelines .  If you haven ’ t already, see  overview  for terminology . The interface is built around the abstract types  Task  and  Method{Task} . Let ’ s give the concepts introduced variable names and types so we can refer to them more easily: task::Task : a task method::Method{Task} : a method implementing a task input::I : an input target::T : a target x::X : an encoded input y::Y : an encoded target ŷ::Ŷ : a model output inputs ,  targets ,  xs ,  ys : batches of the respective data model : a function  (X) -> Ŷ lossfn : a function  (Ŷ, Y) -> Number So a  Task  is an abstract type representing a mapping from some input type  I  to target type  T .  A  Method{T}  implements the task  T  by using encoded representations  X  and  Y . Let ’ s make this more concrete by filling in the types for image classification: task::ImageClassificationTask  (subtype of  Task ) method::ImageClassification  (subtype of  Method{ImageClassificationTask} ) input::AbstractMatrix{2, <:Colorant}  (an image) target::Int  (the category that the image belongs to) x::AbstractArray{Float32, 3} : a normalized 3D - array with dimensions  height, width, channels y::AbstractVector{Float32} : one - hot encoding of category ŷ::AbstractVector{Float32̂} : softmax probabilities","id":"docs/interface.html#methods-interface"},{"body":"DLPipelines","id":"README.html#dlpipelines"},{"body":"public   encode   —   function Encode a  sample  containing both input and target into representations that a model for  task  takes in and outputs, respectively . If  sample  is a  Tuple  of (input, target), the default behavior is to pass them to  encodeinput  and  encodetarget","id":"docstrings/DLPipelines.encode.html"},{"body":"public   encodetarget   —   function Encode  target  into a representation that a model for  task  outputs .","id":"docstrings/DLPipelines.encodetarget.html"},{"body":"public   decodeoutput   —   function","id":"docstrings/DLPipelines.decodeoutput.html"},{"body":"DLPipelines . jl DLPipelines . jl  is an interface for defining deep learning data pipelines .  This includes every data transformation beside the model itself: preprocessing and augmenting the data before feeding it into the model, and decoding the model ’ s outputs to targets . The package was born from the realization that the data pipeline plays a large role in many deep learning projects .  It abstracts the pipeline into steps that lend themselves to building training, inference and other pipelines . Let ’ s get some terminology out of the way . A (supervised)  task  is a learnable mapping from  input s to  target s .  The learnable part of the mapping is represented by a  model . Task Input Target Image classification Image Category Semantic segmentation Image Category per pixel Object detection Image Bounding boxes A  method  is a concrete way to solve a task and defines how inputs and targets are  encoded  into a form that can be fed to and output by the model model outputs are  decoded  to obtain target predictions; and the general model structure, like input and output sizes As an example method, consider the commmon way of approaching the task of  image classification : images are encoded into normalized 3D - Arrays of  Float32 s and categories into one - hot vectors the predicted probability distributions can be decoded into a category by finding the index of the highest score; and the model takes in batches of encoded inputs and output batches of encoded targets An additional complication comes from the fact that the encoding and decoding step may differ based on situation .  For example, during training we often want to apply some augmentation when encoding that would be detrimental to performance during inference . Let ’ s look at the interface provided by  DLPipelines . jl  to represent these abstractions .","id":"docs/overview.html#dlpipelinesjl"},{"body":"Pipelines Now we can break down the steps of the most common pipelines in deep learning . Inference  is simple .  We have an input and obtain a target prediction .  Writing this with types gives us: Training  is a bit more complicated: we have a pair of input and target and want to find out how to update the model parameters such that the model better predicts the target from the input . First, we encode both input and target .  This can also include augmentation .","id":"docs/interface.html#pipelines"},{"body":"private   ImagePreprocessing   —   struct Converts an image to a color, then to a 3D - tensor and finally normalizes the values using  means  and  stds . If no  means  or  stds  are given, use ImageNet statistics .","id":"docstrings/DLPipelines.ImagePreprocessing.html"},{"body":"private   Task   —   parametric type A  Task A  Task  represents a mapping from high - level types  I  to  O .  The learnable part of the mapping is from types  X  to  Y . To give an example, image classification is task that maps images to classes (represented as a matrix of pixels and an integer) .  As inputs and outputs to the learning algorithm, a more optimization - friendly form is used: the image is converted to a normalized 3D array with dimensions (h, w, ch) and the class is converted to a one - hot encoded vector . So, for image classification, we have: In this representation, the pieces to build a training and inference pipeline can be cleanly separated . The first is encoding, i . e .  mapping  I  to  X  and  O  to  Y . The second is decoding, i . e .  mapping Y  - > O . Both of these can highly configurable .  For encoding an input image, we may want to resizing and some stochastic data augmentation, but not during inference . Any configuration/hyperparameters should be stored in the  Task struct which is passed to every method .","id":"docstrings/DLPipelines.Task.html"},{"body":"public   encodeinput   —   function Encode  input  into a representation that a model for  task takes as input .","id":"docstrings/DLPipelines.encodeinput.html"},{"body":"private   SpatialTransforms   —   struct","id":"docstrings/DLPipelines.SpatialTransforms.html"}]