[{"body":"Interfaces Find out how to implement custom  Method s . Core interface , for inference and training pipelines . Interpretation interface .","id":"docs/interfaces/overview.html#interfaces"},{"body":"Types input::AbstractMatrix{2, <:Colorant} : an image target::Int  the category that the image belongs to x::AbstractArray{Float32, 3} : a normalized 3D - array with dimensions  height, width, channels y::AbstractVector{Float32} : one - hot encoding of category","id":"docstrings/DLPipelines.ImageClassification.html#types"},{"body":"DLPipelines DLPipelines . jl  is an interface for defining deep learning data pipelines .  This includes every data transformation beside the model itself: preprocessing and augmenting the data before feeding it into the model, and decoding the model ’ s outputs to targets . The package was born from the realization that the data pipeline plays a large role in many deep learning projects .  It abstracts the pipeline into steps that lend themselves to building training, inference and other pipelines . Start here . DLPipelines . jl  is currently in a pre - implementation phase where the focus is on exploring suitable interfaces .","id":"README.html#dlpipelines"},{"body":"Core interface First you need to  define a custom  Method  (and possibly a  Task ) . Then implement the following functions by dispatching on the method .","id":"docs/interfaces/core.html#core-interface"},{"body":"In code The most important type is  Method  which represents a method for a  Task .  All interface functions will dispatch on  Method .  It should be a concrete  struct  containing necessary configuration . Let ’ s give the other concepts variable names and generic types so we can refer to them more easily: task::Task : a task mapping  I  to  T method::Method{Task} : a method implementing a task using encodings  X  and  Y input::I : an input target::T : a target x::X : an encoded input y::Y : an encoded target ŷ::Ŷ : a model output inputs ,  targets ,  xs ,  ys : batches of the respective data model : a function  (X) -> Ŷ lossfn : a function  (Ŷ, Y) -> Number So a  Task  is an abstract type representing a mapping from some input type  I  to target type  T .  A  Method{T}  implements the task  T  by using encoded representations  X  and  Y . As a concrete example, consider image classification: task::ImageClassificationTask : subtype of  Task method::ImageClassification : subtype of  Method{ImageClassificationTask} input::AbstractMatrix{2, <:Colorant} : an image target::Int  the category that the image belongs to x::AbstractArray{Float32, 3} : a normalized 3D - array with dimensions  height, width, channels y::AbstractVector{Float32} : one - hot encoding of category ŷ::AbstractVector{Float32̂} : softmax probabilities","id":"docs/introduction.html#in-code"},{"body":"Model input size:  (sz..., ch, batch)  where  ch  depends on color type  C . output size:  (nclasses, batch)","id":"docstrings/DLPipelines.ImageClassification.html#model"},{"body":"public   encode   —   function Encode a  sample  containing both input and target  . If  sample  is a  Tuple  of (input, target), the default behavior is to pass them to  encodeinput  and  encodetarget","id":"docstrings/DLPipelines.encode.html"},{"body":"public   encodetarget   —   function Encode  target  into a representation that a model for  task  outputs .","id":"docstrings/DLPipelines.encodetarget.html"},{"body":"Usage From a  Method  implementation, we can derive some useful functionality . predict (method, model, input)  predicts a target from an input dataiter (method, data, batchsize)  creates a data iterator from container  data  using  DataLoaders . jl  that can be used directly in a training loop","id":"docs/usage.html#usage"},{"body":"Remarks When should I implement  encode  vs .   encodeinput  and  encodetarget ? In simple cases like image classification we can encode the inputs and targets separately and you should prefer  encodeinput  and  encodetarget . The default implementation for  encode  when given an  (input, target) - tuple is to delegate to  encodeinput  and  encodetarget . In other cases like semantic segmentation, however, we want to apply stochastic augmentations to both image and segmentation mask .  In that case you need to encode both at the same time using  encode Another situation where  encode  is needed is when  sample  is not a tuple of  (input, target) , for example a  Dict  that includes additional information .   encode  still needs to return an  (x, y) - tuple, though .","id":"docstrings/DLPipelines.encode.html#remarks"},{"body":"private   decodeŷ   —   function Decodes a model output into a target .","id":"docstrings/DLPipelines.decodeŷ.html"},{"body":"Optional functions shouldbatch (method)  defines whether the model for a method should take batches of encoded inputs .  The default is  true .","id":"docs/interfaces/core.html#optional-functions"},{"body":"private   ImagePreprocessing   —   struct Converts an image to a color, then to a 3D - tensor and finally normalizes the values using  means  and  stds . If no  means  or  stds  are given, use ImageNet statistics .","id":"docstrings/DLPipelines.ImagePreprocessing.html"},{"body":"Core pipelines To give a motivation for the interface, consider the two most important pipelines in a deep learning application: training and inference . Note: I ’ m purposely neglecting batching here (for now), as it doesn ’ t change the semantics of the data pipeline, just the practical implementation . During  inference , we have an input and obtain a target prediction .  Writing this with types gives us: When  training , we first encode both input and target, including any augmentation .  We then feed the encoded input to the model and compare its output with the true encoded target . From those two pipelines, we can extract the following transformations: I -> X  encoding input Ŷ -> T  decoding model output (I, T) -> (X, Y)  encoding input and target These make up the  core interface .","id":"docs/introduction.html#core-pipelines"},{"body":"private   Task   —   parametric type A  Task A  Task  represents a mapping from high - level types  I  to  O .  The learnable part of the mapping is from types  X  to  Y . To give an example, image classification is task that maps images to classes (represented as a matrix of pixels and an integer) .  As inputs and outputs to the learning algorithm, a more optimization - friendly form is used: the image is converted to a normalized 3D array with dimensions (h, w, ch) and the class is converted to a one - hot encoded vector . So, for image classification, we have: In this representation, the pieces to build a training and inference pipeline can be cleanly separated . The first is encoding, i . e .  mapping  I  to  X  and  O  to  Y . The second is decoding, i . e .  mapping Y  - > O . Both of these can highly configurable .  For encoding an input image, we may want to resizing and some stochastic data augmentation, but not during inference . Any configuration/hyperparameters should be stored in the  Task struct which is passed to every method .","id":"docstrings/DLPipelines.Task.html"},{"body":"Introduction In supervised deep learning, we ’ re usually trying to solve a problem by finding a mapping from some inputs to some targets .  Let ’ s call this a  task .  Consider for example this table: Task Input Target Image classification Image Category Semantic segmentation Image Category per pixel Object detection Image Bounding boxes Text completion Text Next character There are usually multiple ways to go about solving a task .  We call a  method  a concrete approach to a task that has a learnable part (the model) but also defines how inputs and targets are  encoded  into a form that can be fed to and output by the model model outputs are  decoded  to obtain target predictions; and os an example method, consider the commmon way of approaching the task of image classification: images are encoded into normalized 3D - Arrays of  Float32 s and categories into one - hot vectors the predicted probability distributions can be decoded into a category by finding the index of the highest score; and the model takes in batches of encoded inputs and output batches of encoded targets An additional complication comes from the fact that the encoding and decoding step may differ based on situation .  For example, during training we often want to apply some augmentation when encoding that would be detrimental to performance during inference .","id":"docs/introduction.html#introduction"},{"body":"Remarks What is the  context  argument? We often want to apply data augmentation during training but not during validation or inference .  You can dispatch on  context  to define different behavior for the different situations .  See  PipelineContext  to see the available options . When should I implement  encode  vs .   encodetarget ? See  encode .","id":"docs/interfaces/core.html#remarks"},{"body":"public   ImageClassification   —   struct A  Method  for multi - class image classification using softmax probabilities .","id":"docstrings/DLPipelines.ImageClassification.html"},{"body":"public   encodeinput   —   function Encode  input  into a representation that a model for  task takes as input .","id":"docstrings/DLPipelines.encodeinput.html"},{"body":"Required functions encodeinput (method, context, input) -> x  encodes an input so that it can be fed to a model decodeŷ (method, context, ŷ) -> target  decodes the output of a model into a target either encode (method, context, sample) -> (x, y)  encodes a sample containing input and target so they can be used for a training step encodetarget (method, context, target) -> y encodes a target so that it can be compared to a model output using a loss function","id":"docs/interfaces/core.html#required-functions"},{"body":"Methods DLPipelines . jl  comes with some  Method s already implemented . ImageClassification","id":"docs/methods.html#methods"},{"body":"Transforms Transforms are building blocks that can help you implementing the interfaces for custom  Method s .  Using them is completely optional . SpatialTransforms ImagePreprocessing","id":"docs/transforms.html#transforms"},{"body":"private   SpatialTransforms   —   struct Transformation that resizes images and keypoints to  size . In context  Training , applies  augmentations .","id":"docstrings/DLPipelines.SpatialTransforms.html"}]